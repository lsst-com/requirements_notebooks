{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plot_color_mesh\n",
    "from utils import select_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "repo_dir = '/datasets/hsc/repo/rerun/RC/w_2019_30/DM-20525'\n",
    "assert os.path.isdir(repo_dir)\n",
    "\n",
    "import lsst.daf.persistence as daf_persistence\n",
    "butler = daf_persistence.Butler(repo_dir)\n",
    "\n",
    "import lsst.verify as lsst_verify\n",
    "import astropy.units as astropy_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_dir = 'verify_photometry'\n",
    "metric_set = lsst_verify.MetricSet.load_metrics_package(verify_dir)\n",
    "spec_set = lsst_verify.SpecificationSet.load_metrics_package(verify_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(metric_set))\n",
    "print(len(spec_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'photometric_repeatability.PA1uzy', 'description': 'The RMS photometric repeatability of bright non-saturated unresolved point sources in u, z, and y filters.', 'unit': 'mag', 'tags': [], 'reference': {'doc': 'LSE-030', 'page': None, 'url': None}}, {'name': 'photometric_repeatability.PA1gri', 'description': 'The RMS photometric repeatability of bright non-saturated unresolved point sources in g, r, and i filters.', 'unit': 'mag', 'tags': [], 'reference': {'doc': 'LSE-030', 'page': None, 'url': None}}, {'name': 'photometric_repeatability.PF1', 'description': 'The maximum fraction of isolated non-saturated point source measurements exceeding the outlier limit.', 'unit': '', 'tags': [], 'reference': {'doc': 'LSE-030', 'page': None, 'url': None}}]\n"
     ]
    }
   ],
   "source": [
    "print(metric_set.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coadd_skymap = butler.get('deepCoadd_skyMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(coadd_skymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(coadd_skymap.findTractPatchList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# this file contains the minimum and maximum RA, Dec values for each\n",
    "# visit that actually exists in the HSC UDEEP rerun\n",
    "spatial_lookup_filename = '/project/danielsf/valid_hsc_visit_extent_DM_20525.h5'\n",
    "assert os.path.isfile(spatial_lookup_filename)\n",
    "spatial_lookup = h5py.File(spatial_lookup_filename, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a (somewhat arbitrary) region on the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_num = spatial_lookup['visit'][11625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visit = np.where(spatial_lookup['visit'][()]==visit_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "print(len(all_visit[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_min = spatial_lookup['ra_min'][()][all_visit].min()\n",
    "ra_max = spatial_lookup['ra_max'][()][all_visit].max()\n",
    "dec_min = spatial_lookup['dec_min'][()][all_visit].min()\n",
    "dec_max = spatial_lookup['dec_max'][()][all_visit].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coverage = np.where(np.logical_and(spatial_lookup['ra_center'][()]>ra_min,\n",
    "                        np.logical_and(spatial_lookup['ra_center'][()]<ra_max,\n",
    "                        np.logical_and(spatial_lookup['dec_center'][()]>dec_min,\n",
    "                                       spatial_lookup['dec_center'][()]<dec_max))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the (tract, patch) pairs in that region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.geom as lsst_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list = []\n",
    "for ra in np.arange(ra_min, ra_max, 0.005):\n",
    "    for dec in np.arange(dec_min, dec_max, 0.005):\n",
    "        pt_list.append(lsst_geom.SpherePoint(ra, dec, lsst_geom.radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_patch_list = coadd_skymap.findTractPatchList(pt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to select stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the clear stars from the deepCoadd_forcedSrc catalog.  Plot the stellar locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielsf/requirements_notebooks/TestCases/utils/query_utils.py:32: RuntimeWarning: invalid value encountered in less\n",
      "  mag_m_model_flag = np.abs(mag-model_mag)<0.03\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coadd_unq_id = []\n",
    "coadd_g_mags = []\n",
    "coadd_r_mags = []\n",
    "coadd_i_mags = []\n",
    "\n",
    "coadd_g_model = []\n",
    "coadd_r_model = []\n",
    "coadd_i_model = []\n",
    "\n",
    "coadd_ra = []\n",
    "coadd_dec = []\n",
    "\n",
    "coadd_full_ra = []\n",
    "coadd_full_dec = []\n",
    "coadd_full_stars = []\n",
    "\n",
    "ct_full_src = 0\n",
    "\n",
    "for tract_sublist in tract_patch_list:\n",
    "    tract_id = tract_sublist[0].getId()\n",
    "    for patch_obj in tract_sublist[1]:\n",
    "        patch_id = str(patch_obj.getIndex()).replace('(','').replace(')','').replace(' ','')\n",
    "        blank_data_id = {'tract': tract_id, 'patch':patch_id}\n",
    "\n",
    "        data_id_g = copy.deepcopy(blank_data_id)\n",
    "        data_id_g['filter'] = 'HSC-G'\n",
    "        data_id_r = copy.deepcopy(blank_data_id)\n",
    "        data_id_r['filter'] = 'HSC-R'\n",
    "        data_id_i = copy.deepcopy(blank_data_id)\n",
    "        data_id_i['filter'] = 'HSC-I'\n",
    "\n",
    "        if not butler.datasetExists('deepCoadd_forced_src', dataId=data_id_g):\n",
    "            continue\n",
    "\n",
    "        if not butler.datasetExists('deepCoadd_forced_src', dataId=data_id_r):\n",
    "            continue\n",
    "\n",
    "        if not butler.datasetExists('deepCoadd_forced_src', dataId=data_id_i):\n",
    "            continue\n",
    "        #print('loading %s' % str(blank_data_id))\n",
    "        \n",
    "        data_g = butler.get('deepCoadd_forced_src', dataId=data_id_g)#.asAstropy()\n",
    "        data_r = butler.get('deepCoadd_forced_src', dataId=data_id_r)#.asAstropy()\n",
    "        data_i = butler.get('deepCoadd_forced_src', dataId=data_id_i)#.asAstropy()\n",
    "\n",
    "        np.testing.assert_array_equal(data_g['id'], data_r['id'])\n",
    "        np.testing.assert_array_equal(data_g['id'], data_i['id'])\n",
    "        np.testing.assert_array_equal(data_g['coord_ra'], data_r['coord_ra'])\n",
    "        np.testing.assert_array_equal(data_g['coord_ra'], data_i['coord_ra'])\n",
    "        np.testing.assert_array_equal(data_g['coord_dec'], data_r['coord_dec'])\n",
    "        np.testing.assert_array_equal(data_g['coord_dec'], data_r['coord_dec'])\n",
    "\n",
    "        calib_g = butler.get('deepCoadd_calexp_photoCalib', dataId=data_id_g)\n",
    "        calib_r = butler.get('deepCoadd_calexp_photoCalib', dataId=data_id_r)\n",
    "        calib_i = butler.get('deepCoadd_calexp_photoCalib', dataId=data_id_i)\n",
    "    \n",
    "        g_mag, g_mag_error, g_model, star_g = select_stars(data_g, calib_g)\n",
    "        r_mag, r_mag_error, r_model, star_r = select_stars(data_r, calib_r)\n",
    "        i_mag, i_mag_error, i_model, star_i = select_stars(data_i, calib_i)\n",
    "        stars = star_g & star_r & star_i\n",
    "\n",
    "        coadd_g_mags.append(g_mag[stars])\n",
    "        coadd_g_model.append(g_model[stars])\n",
    "        coadd_r_mags.append(r_mag[stars])\n",
    "        coadd_r_model.append(r_model[stars])\n",
    "        coadd_i_mags.append(i_mag[stars])\n",
    "        coadd_i_model.append(i_model[stars])\n",
    "    \n",
    "        coadd_ra.append(data_g['coord_ra'][stars])\n",
    "        coadd_dec.append(data_g['coord_dec'][stars])\n",
    "        coadd_unq_id.append(data_g['id'][stars])\n",
    "        coadd_full_ra.append(data_g['coord_ra'])\n",
    "        coadd_full_dec.append(data_g['coord_dec'])\n",
    "        coadd_full_stars.append(stars)\n",
    "\n",
    "        ct_full_src += len(data_g['coord_ra'])    \n",
    "\n",
    "        #coadd_g_mags.append(calib_g.instFluxToMagnitude(data_g['base_PsfFlux_instFlux']))\n",
    "        #coadd_r_mags.append(calib_r.instFluxToMagnitude(data_r['base_PsfFlux_instFlux']))\n",
    "        #coadd_i_mags.append(calib_i.instFluxToMagnitude(data_i['base_PsfFlux_instFlux']))\n",
    "\n",
    "    \n",
    "coadd_unq_id = np.concatenate(coadd_unq_id)\n",
    "coadd_ra = np.concatenate(coadd_ra)\n",
    "coadd_dec = np.concatenate(coadd_dec)\n",
    "coadd_g_mags = np.concatenate(coadd_g_mags)\n",
    "coadd_r_mags = np.concatenate(coadd_r_mags)\n",
    "coadd_i_mags = np.concatenate(coadd_i_mags)\n",
    "coadd_g_model = np.concatenate(coadd_g_model)\n",
    "coadd_r_model = np.concatenate(coadd_r_model)\n",
    "coadd_i_model = np.concatenate(coadd_i_model)\n",
    "\n",
    "coadd_full_ra = np.concatenate(coadd_full_ra)\n",
    "coadd_full_dec = np.concatenate(coadd_full_dec)\n",
    "coadd_full_stars = np.concatenate(coadd_full_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coadd_g_mags))\n",
    "print(len(coadd_full_ra))\n",
    "print(ct_full_src)\n",
    "#print(data_g.getSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "#plt.scatter(coadd_g_mags, coadd_g_mags-coadd_g_model)\n",
    "plot_color_mesh(coadd_g_mags, coadd_g_mags-coadd_g_model, 0.002, 0.001)\n",
    "plt.xlabel('g(PSF)')\n",
    "plt.ylabel('g(PSF)-g(cModel)')\n",
    "plt.ylim(-0.03,0.03)\n",
    "plt.show()\n",
    "print(coadd_g_mags.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "#plt.scatter(coadd_g_mags-coadd_r_mags, coadd_r_mags-coadd_i_mags,s=0.5)\n",
    "valid_meas = np.logical_and(np.isfinite(coadd_g_mags),\n",
    "                 np.logical_and(np.isfinite(coadd_r_mags), np.isfinite(coadd_i_mags)))\n",
    "\n",
    "bright_enough = np.logical_and(coadd_g_mags<25.0,\n",
    "                np.logical_and(coadd_r_mags<25.0, coadd_i_mags<25.0))\n",
    "\n",
    "valid = np.where(np.logical_and(valid_meas, bright_enough))\n",
    "print(len(valid[0]))\n",
    "#plt.scatter(coadd_g_mags-coadd_r_mags,\n",
    "#            coadd_r_mags-coadd_i_mags,s=0.5)\n",
    "\n",
    "plot_color_mesh(coadd_g_mags-coadd_r_mags,\n",
    "                coadd_r_mags-coadd_i_mags,\n",
    "               0.02, 0.02)\n",
    "\n",
    "#plt.hist2d(coadd_g_mags[valid]-coadd_r_mags[valid],\n",
    "#           coadd_r_mags[valid]-coadd_i_mags[valid], bins=(200,200), cmap=plt.cm.jet)\n",
    "plt.xlabel('g-r')\n",
    "plt.ylabel('r-i')\n",
    "#plt.ylim(20,35)\n",
    "#plt.xlim(-5,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a KDTree of these sources for association with single image sources later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as scipy_spatial\n",
    "cdec = np.cos(coadd_full_dec)\n",
    "coadd_spatial_data = np.array([cdec*np.cos(coadd_full_ra),\n",
    "                               cdec*np.sin(coadd_full_ra),\n",
    "                               np.sin(coadd_full_dec)]).transpose()\n",
    "coadd_spatial_tree = scipy_spatial.cKDTree(coadd_spatial_data, leafsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the single calexp visits in G, R, I that overlap the coadd region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_visits = 0\n",
    "s_ra_min = spatial_lookup['ra_min'][()]\n",
    "s_ra_max= spatial_lookup['ra_max'][()]\n",
    "s_dec_min = spatial_lookup['dec_min'][()]\n",
    "s_dec_max = spatial_lookup['dec_max'][()]\n",
    "s_filter = spatial_lookup['filter'][()]\n",
    "s_visit = spatial_lookup['visit'][()]\n",
    "s_ccd = spatial_lookup['ccd'][()]\n",
    "fset = set([b'HSC-G', b'HSC-R', b'HSC-I', b'HSC-Z', b'HSC-Y'])\n",
    "desired_data_id_list = []\n",
    "for rmin, rmax, dmin, dmax, fname, vv, ccd in \\\n",
    "zip(s_ra_min, s_ra_max, s_dec_min, s_dec_max, s_filter, s_visit, s_ccd):\n",
    "    if fname not in fset:\n",
    "        continue\n",
    "    valid = (coadd_ra>=rmin) & (coadd_ra<=rmax) & (coadd_dec>=dmin) & (coadd_dec<=dmax)\n",
    "    if np.sum(valid)>0:\n",
    "        ct_visits += 1\n",
    "        data_id = {'filter': fname.decode(), 'ccd': int(ccd), 'visit': int(vv)}\n",
    "        desired_data_id_list.append(data_id)\n",
    "print(ct_visits)\n",
    "print(len(desired_data_id_list))\n",
    "print(len(s_ra_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a method so that we can load the calexp data in parallel with multiprocessing\n",
    "\n",
    "import time\n",
    "def load_data_id(data_id_list, output_dict, my_lock, repo_dir):\n",
    "\n",
    "    t_start = time.time()\n",
    "    assert os.path.isdir(repo_dir)\n",
    "\n",
    "    local_butler = daf_persistence.Butler(repo_dir)\n",
    "    print('PID %d considering %d data_ids (butler loaded in %e seconds)' %\n",
    "          (os.getpid(),len(data_id_list),time.time()-t_start))\n",
    "    t_start = time.time()\n",
    "    ct_good = 0\n",
    "    ct_bad = 0\n",
    "    n_visits = len(data_id_list)\n",
    "    local_ra = []\n",
    "    local_dec = []\n",
    "    local_mag = []\n",
    "    local_mag_error = []\n",
    "    local_filter=  []\n",
    "\n",
    "    for data_id_single in data_id_list:\n",
    "        data_single = local_butler.get('src', dataId=data_id_single, immediate=True)\n",
    "        tract_id_list = []\n",
    "        for ra, dec in zip(data_single['coord_ra'], data_single['coord_dec']):\n",
    "            pt = lsst_geom.SpherePoint(ra, dec, lsst_geom.radians)\n",
    "            tract_id_list.append(coadd_skymap.findTract(pt).getId())\n",
    "        tract_id_list = np.array(tract_id_list)\n",
    "        unq_tract_id_list = np.unique(tract_id_list)\n",
    "        for tract_id in unq_tract_id_list:\n",
    "            is_tract = (tract_id_list==tract_id)\n",
    "            \n",
    "            data_id_single['tract'] = int(tract_id)\n",
    "            try:\n",
    "                calib_single = local_butler.get('jointcal_photoCalib',\n",
    "                                                dataId=data_id_single)\n",
    "            except:\n",
    "                continue\n",
    "            wcs = local_butler.get('jointcal_wcs', dataId=data_id_single)\n",
    "\n",
    "            active_data = data_single[is_tract]\n",
    "            for record in active_data:\n",
    "                record.updateCoord(wcs)\n",
    "\n",
    "            psf_mag, psf_mag_error, model_mag, star_dex = select_stars(active_data,\n",
    "                                                                       calib_single,\n",
    "                                                                       has_cmodel=False)\n",
    "        \n",
    "            local_ra.append(active_data['coord_ra'][star_dex])\n",
    "            local_dec.append(active_data['coord_dec'][star_dex])\n",
    "            local_mag.append(psf_mag[star_dex])\n",
    "            local_mag_error.append(psf_mag_error[star_dex])\n",
    "            local_filter.append([data_id_single['filter']]*np.sum(star_dex))\n",
    "            assert len(local_filter[-1]) == len(local_ra[-1])\n",
    "        \n",
    "        ct_good += 1\n",
    "    duration = (time.time()-t_start)/3600.0\n",
    "    print('good: %d bad: %d in %.2e hrs' % (ct_good, ct_bad, duration))\n",
    "\n",
    "    if len(local_ra)>0:\n",
    "        with my_lock:\n",
    "            output_dict['ra'] += local_ra\n",
    "            output_dict['dec'] += local_dec\n",
    "            output_dict['filter'] += local_filter\n",
    "            output_dict['mag'] += local_mag\n",
    "            output_dict['mag_error'] += local_mag_error\n",
    "    #print('%d is done good: %d bad: %d' % (os.getpid(),ct_good,ct_bad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the RA, Dec, magnitue, and filter of all of the single image stars in HSC UDEEP\n",
    "\n",
    "(This will take about five minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import multiprocessing\n",
    "\n",
    "mgr = multiprocessing.Manager()\n",
    "my_lock = mgr.Lock()\n",
    "output_dict = mgr.dict()\n",
    "butler_dict = mgr.dict()\n",
    "for k in ['ra', 'dec', 'mag', 'mag_error', 'filter']:\n",
    "    output_dict[k] = mgr.list()\n",
    "\n",
    "t_start = time.time()\n",
    "single_ra = []\n",
    "single_dec = []\n",
    "single_mag = []\n",
    "single_mag_error= []\n",
    "single_model_mag = []\n",
    "single_filter = []\n",
    "ct_single = 0\n",
    "n_visits = len(desired_data_id_list)\n",
    "\n",
    "n_fourth = n_visits//4\n",
    "print(n_visits, n_fourth)\n",
    "p_list = []\n",
    "\n",
    "#test_data_id_list = desired_data_id_list[:800]\n",
    "#n_visits = len(test_data_id_list)\n",
    "\n",
    "\n",
    "#load_data_id(desired_data_id_list[:10], output_dict, my_lock, repo_dir)\n",
    "\n",
    "\n",
    "d_data_id=500\n",
    "for i_start in range(0,n_visits,d_data_id):\n",
    "    p = multiprocessing.Process(target=load_data_id,\n",
    "                                args=[desired_data_id_list[i_start:i_start+d_data_id],\n",
    "                                      output_dict, my_lock, repo_dir])\n",
    "\n",
    "    p.start()\n",
    "    p_list.append(p)\n",
    "    while len(p_list)>=4:\n",
    "        exit_code_list = []\n",
    "        for p in p_list:\n",
    "            exit_code_list.append(p.exitcode)\n",
    "        for i_p in range(len(exit_code_list)-1, -1, -1):\n",
    "            if exit_code_list[i_p] is not None:\n",
    "                p_list.pop(i_p)\n",
    "\n",
    "for p in p_list:\n",
    "    p.join()\n",
    "\n",
    "single_ra = np.concatenate(output_dict['ra'])\n",
    "single_dec = np.concatenate(output_dict['dec'])\n",
    "single_mag = np.concatenate(output_dict['mag'])\n",
    "single_mag_error = np.concatenate(output_dict['mag_error'])\n",
    "single_filter = np.concatenate(output_dict['filter'])\n",
    "\n",
    "\n",
    "print('all done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(single_ra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate single image sources with coadd forced sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First associate single detections with all coadd sources (not just stars) and only select those whose nearest neighbor is a star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdec = np.cos(single_dec)\n",
    "single_spatial_data = np.array([cdec*np.cos(single_ra),\n",
    "                                cdec*np.sin(single_ra),\n",
    "                                np.sin(single_dec)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fit_dist, raw_fit_dex = coadd_spatial_tree.query(single_spatial_data, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only sources whose nearest neighbor has been identified as a star in the coadd,\n",
    "# who are within 0.05 arcsec of their nearest neighbor\n",
    "# and are 10 times closer to their nearest neighbor than to their second nearest neighbor\n",
    "# and are at least 2 arcsec away from their second nearest neighbor\n",
    "\n",
    "raw_fit_d_trans = raw_fit_dist.transpose()\n",
    "raw_fit_d_ratio = raw_fit_d_trans[0]/raw_fit_d_trans[1]\n",
    "raw_fit_d_arcsec= raw_fit_d_trans[0]/np.radians(1/3600)\n",
    "raw_fit_d2_arcsec = raw_fit_d_trans[1]/np.radians(1/3600)\n",
    "raw_fit_is_star = coadd_full_stars[raw_fit_dex.transpose()[0]]\n",
    "\n",
    "assoc_to_stars = np.where(np.logical_and(raw_fit_d_ratio<0.1,\n",
    "                          np.logical_and(raw_fit_d_arcsec<0.05,\n",
    "                          np.logical_and(raw_fit_d2_arcsec>2.0,\n",
    "                                         raw_fit_is_star))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(assoc_to_stars[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select down to only those single exposure sources that were associated with stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ra_stellar = single_ra[assoc_to_stars]\n",
    "single_dec_stellar = single_dec[assoc_to_stars]\n",
    "single_mag_stellar = single_mag[assoc_to_stars]\n",
    "single_mag_error_stellar = single_mag_error[assoc_to_stars]\n",
    "single_filter_stellar = single_filter[assoc_to_stars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-do the nearest neighbor fit, only checking against coadd stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdec = np.cos(single_dec_stellar)\n",
    "single_spatial_data = np.array([cdec*np.cos(single_ra_stellar),\n",
    "                                cdec*np.sin(single_ra_stellar),\n",
    "                                np.sin(single_dec_stellar)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cdec = np.cos(coadd_dec)\n",
    "coadd_stellar_spatial = np.array([np.cos(coadd_ra)*cdec,\n",
    "                                  np.sin(coadd_ra)*cdec,\n",
    "                                  np.sin(coadd_dec)]).transpose()\n",
    "coadd_spatial_tree_stellar = scipy_spatial.cKDTree(coadd_stellar_spatial, leafsize=16)\n",
    "fit_dist, fit_dex = coadd_spatial_tree_stellar.query(single_spatial_data, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only those stars that are within 0.05 arcseconds of a coadd force source\n",
    "# and for whom the nearest neighbor is 10 times closer than the next nearest neighbor\n",
    "\n",
    "fit_d_trans = fit_dist.transpose()\n",
    "fit_d_ratio = fit_d_trans[0]/fit_d_trans[1]\n",
    "fit_d_arcsec= fit_d_trans[0]/np.radians(1/3600)\n",
    "fit_d2_arcsec = fit_d_trans[1]/np.radians(1/3600)\n",
    "print(fit_d2_arcsec.min())\n",
    "\n",
    "valid = np.where(np.logical_and(fit_d_ratio<0.1,\n",
    "                 np.logical_and(fit_d2_arcsec>2.0,\n",
    "                                fit_d_arcsec<0.05,)))\n",
    "np.testing.assert_array_equal(valid[0], np.arange(0,len(single_ra_stellar), dtype=int))\n",
    "\n",
    "single_ra_stellar = single_ra_stellar[valid]\n",
    "single_dec_stellar = single_dec_stellar[valid]\n",
    "single_mag_stellar = single_mag_stellar[valid]\n",
    "single_mag_error_stellar = single_mag_stellar[valid]\n",
    "single_filter_stellar = single_filter_stellar[valid]\n",
    "single_fit_dex = fit_dex[:,0][valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that sources are correctly associated\n",
    "\n",
    "d_max = -1.0\n",
    "for sra, sdec, dex in zip(single_ra_stellar, single_dec_stellar, single_fit_dex):\n",
    "    cdec = np.cos(sdec)\n",
    "    xyz_s = np.array([cdec*np.cos(sra), cdec*np.sin(sra), np.sin(sdec)])\n",
    "    \n",
    "    cdec = np.cos(coadd_dec[dex])\n",
    "    cra = coadd_ra[dex]\n",
    "    xyz_c = np.array([cdec*np.cos(cra), cdec*np.sin(cra), np.sin(coadd_dec[dex])])\n",
    "    dot_prod = np.dot(xyz_s, xyz_c)\n",
    "    dd = np.arccos(dot_prod)/np.radians(1.0/3600.0)\n",
    "    if dd>d_max:\n",
    "        d_max = dd\n",
    "        print('d_max %.2e arcsec' % d_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coadd_mag_dict = {'HSC-G': coadd_g_mags,\n",
    "                 'HSC-R': coadd_r_mags,\n",
    "                 'HSC-I': coadd_i_mags}\n",
    "bp_list = ['HSC-G', 'HSC-R', 'HSC-I', 'HSC-Z', 'HSC-Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HSC-I' in single_filter_stellar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare single calexp magnitudes to coadd magnitudes\n",
    "\n",
    "for bp in bp_list:\n",
    "    if bp not in coadd_mag_dict:\n",
    "        continue\n",
    "    valid = np.where(np.char.find(single_filter_stellar, bp)==0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    s = single_mag_stellar[valid]\n",
    "    plot_color_mesh(s,\n",
    "                    coadd_mag_dict[bp][single_fit_dex[valid]],\n",
    "                    0.04, 0.04)\n",
    "    plt.plot([s.min(),s.max()], [s.min(),s.max()], linestyle='--',\n",
    "             color='y', zorder=3)\n",
    "    plt.xlabel('calexp %s magnitude' % bp, fontsize=20)\n",
    "    plt.ylabel('coadd %s magnitude' % bp, fontsize=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa1_limit = {}\n",
    "pa1_limit['HSC-G'] = 0.005\n",
    "pa1_limit['HSC-R'] = 0.005\n",
    "pa1_limit['HSC-I'] = 0.005\n",
    "pa1_limit['HSC-Z'] = 0.0075\n",
    "pa1_limit['HSC-Y'] = 0.0075\n",
    "\n",
    "pa2_limit = {}\n",
    "pa2_limit['HSC-G'] = 0.015\n",
    "pa2_limit['HSC-R'] = 0.015\n",
    "pa2_limit['HSC-I'] = 0.015\n",
    "pa2_limit['HSC-Z'] = 0.0225\n",
    "pa2_limit['HSC-Y'] = 0.0225\n",
    "\n",
    "pf1 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rms = {}\n",
    "outlier_frac = {}\n",
    "\n",
    "measurement_dict = {}\n",
    "\n",
    "for bp in bp_list:\n",
    "    mag_scatter = []\n",
    "    mag_coadd_scatter = []\n",
    "    mag_rms = []\n",
    "    is_filter = np.where(np.char.find(single_filter_stellar, bp)==0)\n",
    "    mag = single_mag_stellar[is_filter]\n",
    "    dex = single_fit_dex[is_filter]\n",
    "    unq_id_list = np.unique(single_fit_dex)\n",
    "    for unq_id in unq_id_list:\n",
    "        is_obj = np.where(dex==unq_id)\n",
    "        mag_arr = mag[is_obj]\n",
    "        mean_mag = np.mean(mag_arr)\n",
    "        mag_scatter.append(mag_arr-mean_mag)\n",
    "        if bp in coadd_mag_dict:\n",
    "            mag_coadd_scatter.append(mag_arr-coadd_mag_dict[bp][unq_id])\n",
    "        if len(mag_arr) > 10:\n",
    "            mag_rms.append(np.std(mag_arr))\n",
    "    mag_scatter = np.concatenate(mag_scatter)\n",
    "    if bp in coadd_mag_dict:\n",
    "        mag_coadd_scatter = np.concatenate(mag_coadd_scatter)\n",
    "    mag_rms = np.array(mag_rms)\n",
    "    assert len(mag)==len(mag_scatter)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(mag_scatter, bins=50, label='baseline=mean', zorder=0, color='b')\n",
    "    if bp in coadd_mag_dict:\n",
    "        plt.hist(mag_coadd_scatter, bins=50, label='baseline=coadd', zorder=1, alpha=0.5, color='r')\n",
    "    plt.xlabel('mag - baseline  %s' % bp, fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #plt.xticks(fontsize=15)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.hist(mag_rms, bins=50)\n",
    "    plt.axvline(pa1_limit[bp], linestyle='--', color='r')\n",
    "    plt.xlabel('RMS(mag)  %s' % bp, fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #plt.xticks(fontsize=15)\n",
    "    \n",
    "    median_rms[bp] = np.median(mag_rms)\n",
    "    outliers = np.where(mag_rms>pa2_limit[bp])\n",
    "    outlier_frac[bp] = len(outliers[0])/len(mag_rms)\n",
    "\n",
    "    lsst_bp = bp[-1].lower()\n",
    "    if lsst_bp in 'uzy':\n",
    "        pa_tag = 'uzy'\n",
    "    elif lsst_bp in 'gri':\n",
    "        pa_tag = 'gri'\n",
    "    else:\n",
    "        raise RuntimeError(\"not sure how to handle lsst_bp %s\" % lsst_bp)\n",
    "\n",
    "    meas_pa1 = lsst_verify.Measurement('photometric_repeatability.PA1%s' % pa_tag,\n",
    "                                       np.median(mag_rms)*astropy_units.mag, notes={'bandpass': bp})\n",
    "    meas_pf1 = lsst_verify.Measurement('photometric_repeatability.PF1',\n",
    "                                       np.sum(mag_rms>pa2_limit[bp])/len(mag_rms),\n",
    "                                       notes={'bandpass': bp})\n",
    "    \n",
    "    measurement_dict['pa1_%s' % lsst_bp] = meas_pa1\n",
    "    measurement_dict['pf1_%s' % lsst_bp] = meas_pf1\n",
    "\n",
    "    xcoord = mag_rms.min()+0.3*(mag_rms.max()-mag_rms.min())\n",
    "    ycoord = plt.ylim()[0]+0.75*(plt.ylim()[1]-plt.ylim()[0])\n",
    "    plt.text(xcoord,ycoord,'median RMS\\n%.2e mmag\\n\\noutlier fraction\\n%.2e' %\n",
    "             (median_rms[bp]*1000.0, outlier_frac[bp]),fontsize=20)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = []\n",
    "for bp in 'grizy':\n",
    "    if bp in 'uzy':\n",
    "        pa1_name = 'PA1uzy'\n",
    "    else:\n",
    "        pa1_name = 'PA1gri'\n",
    "\n",
    "    #metric_subset = lsst_verify.MetricSet([metric_set['relative_photometry.%s' % pa1_name,\n",
    "    #                                                  'relative_photometry.PF1']])\n",
    "    pa1_metric = metric_set['photometric_repeatability.%s' % pa1_name]\n",
    "    pf1_metric = metric_set['photometric_repeatability.PF1']\n",
    "    metric_subset = lsst_verify.MetricSet([pa1_metric, pf1_metric])\n",
    "\n",
    "    measurement_list = [measurement_dict['pa1_%s' % bp],\n",
    "                        measurement_dict['pf1_%s' % bp]]\n",
    "    #print(measurement_list[0].json)\n",
    "    #print(spec_set.json)\n",
    "    job = lsst_verify.Job(metrics=metric_subset, specs=spec_set, measurements=measurement_list)\n",
    "    job_list.append(job)\n",
    "\n",
    "    print(bp)\n",
    "    print(job.json)\n",
    "    print('\\n')\n",
    "    \n",
    "    #job.report().show()\n",
    "    #print(job.report().make_table())\n",
    "    #print('all done')\n",
    "    #break\n",
    "#for m in measurement_list:\n",
    "#    job.measurements.insert(m)\n",
    "#    print(len(job.measurements))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_api_url = \"https://squash-restful-api-sandbox.lsst.codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getuser()\n",
    "password = getpass.getpass(prompt='Password for user `{}`: '.format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "credentials = {'username': username, 'password': password}\n",
    "r = requests.post('{}/auth'.format(squash_api_url), json=credentials)\n",
    "#r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Authorization': 'JWT {}'.format(r.json()['access_token'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post('{}/metrics'.format(squash_api_url),\n",
    "                json={'metrics': metric_set.json},\n",
    "                headers=headers)\n",
    "r.json()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = requests.post('{}/specs'.format(squash_api_url),\n",
    "                json={'specs': spec_set.json},\n",
    "                headers=headers)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in job_list:\n",
    "    job.meta.update({'packages': {}})\n",
    "    job.meta.update({'env': {'env_name': 'jenkins'}})\n",
    "    job.dispatch(api_user=username, api_password=password, api_url=squash_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(job.dispatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.table as astropy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(astropy_table.Table.show_in_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job.measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = butler.get('src', dataId=desired_data_id_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.where(np.abs(mag_coadd_scatter)<0.05)\n",
    "print(len(valid[0]))\n",
    "print(mag_rms.min())\n",
    "print(len(mag_coadd_scatter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.getKeys('jointcal_photoCalib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.getKeys('jointcal_wcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in tract_patch_list:\n",
    "    print(tt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(coadd_skymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coadd_skymap.findTract(pt_list[1]).getId()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = {'filter': 'HSC-I', 'ccd': 0, 'visit': 7274, 'tract': 8523}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.datasetExists('jointcal_photoCalib', dataId=data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = butler.get('jointcal_photoCalib', dataId=data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(butler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.queryMetadata('jointcal_photoCalib', ['visit', 'ccd', 'filter', 'tract'], dataId=data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lsst_verify.Job.measurements.setter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
