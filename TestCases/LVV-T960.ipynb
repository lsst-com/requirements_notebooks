{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LVV-T960: Relative Astrometric Performance\n",
    "\n",
    "**Written By: Bryce Kalmbach**\n",
    "\n",
    "**Last updated: 07-22-2019**\n",
    "\n",
    "**Tested on Stack Version: w_2019_28**\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "[OSS-REQ-0388](https://docushare.lsst.org/docushare/dsweb/Get/LSE-030#page=68)\n",
    "\n",
    "1. For all pairs of sources separated by ~5 arcminutes median error in these measurements is <= 10 milliarcseconds.\n",
    "\n",
    "2. No more than 10% of the source pairs separated by ~5 arcminutes have separation errors greater than 20 milliarcseconds.\n",
    "\n",
    "3. For all pairs of sources separated by ~20 arcminutes median error in these measurements is <= 10 milliarcseconds.\n",
    "\n",
    "4. No more than 10% of the source pairs separated by ~20 arcminutes have separation errors greater than 20 milliarcseconds.\n",
    "\n",
    "5. For all pairs of sources separated by ~200 arcminutes median error in these measurements is <= 15 milliarcseconds.\n",
    "\n",
    "6. No more than 10% of the source pairs separated by ~200 arcminutes have separation errors greater than 30 milliarcseconds.\n",
    "\n",
    "## Proposed Test Case:\n",
    "\n",
    "1. Image a region that overlaps the Gaia footprint (we will use Gaia as astrometric truth).  Repeat at different airmasses.\n",
    "\n",
    "2. Run source detection and astrometric measurement on images from step 1\n",
    "\n",
    "3. Calculate the separation between all sources detected in step 2\n",
    "\n",
    "4. Compare source separations from step 3 to the same source separations as measured by Gaia\n",
    "\n",
    "5. Examine distribution of source separation errors from step 4 for all pairs of sources separated by ~5 arcminutes.  Verify that the median error in these measurements is <= 10 milliarcseconds\n",
    "\n",
    "6. Verify that no more than 10% of the source pairs separated by ~5 arcminutes have separation errors greater than 20 milliarcseconds\n",
    "\n",
    "7. Examine distribution of source separation errors from step 4 for all pairs of sources separated by ~20 arcminutes.  Verify that the median error in these measurements is <= 10 milliarcseconds\n",
    "\n",
    "8. Verify that no more than 10 percent of source pairs separated by ~20 arcminutes have source separation errors greater than 20 milliarcseconds\n",
    "\n",
    "9. Examine distribution of source separation errors from step 4 for all pairs separated by ~200 arcminutes.  Verify that the median error in these measurements is <= 15 milliarcseconds.\n",
    "\n",
    "10. Verify that no more than 10 percent of sources separated by ~200 arcminutes have source separation errors greater than 30 milliarcseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.daf.persistence import Butler\n",
    "import lsst.daf.persistence as daf_persistence\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our plots nice and readable\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for testing\n",
    "\n",
    "* `test_bandpass`: The notebook will set up to test astrometry in this bandpass against 'r'\n",
    "\n",
    "* `faint_mag_lim`: If set to `None`, the notebook will calculate separations for every pair of objects that are present in all visits. This can take a long time or perhaps we want to see how astrometry changes as a function of magnitude. Therefore, we can set this to only keep sources with a magnitude brighter than this limit in the `test_bandpass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bandpass = 'HSC-R'\n",
    "\n",
    "faint_mag_lim = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify HSC Data to use\n",
    "\n",
    "We want to get data from a single visit for this requirement so we choose a visit from the HSC Wide dataset. https://hsc-release.mtk.nao.ac.jp/doc/index.php/database/ has info \n",
    "on which tracts are included in the Wide data. We randomly choose tract 9348 for testing. To choose a different band for testing change `band` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a butler for the HSC Wide data\n",
    "depth = 'WIDE'\n",
    "band = test_bandpass\n",
    "butler = daf_persistence.Butler('/datasets/hsc/repo/rerun/DM-13666/%s/'%(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a visit in the WIDE data for specified band in the tract 9348\n",
    "warp_list = os.listdir('/datasets/hsc/repo/rerun/DM-13666/WIDE/deepCoadd/%s/9348/0,0' % band)\n",
    "warp_list.sort()\n",
    "visit = int(warp_list[0].split('-')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = butler.subset('src', filter=band, visit=visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in sources from visit making exceptions for bad ccd 9 and focusing ccds.\n",
    "hsc_sources_df = None\n",
    "ccd_lims = []\n",
    "for dataId in subset.cache:\n",
    "    if dataId['ccd'] % 10 == 0:\n",
    "        print('On CCD #%i' % dataId['ccd'])\n",
    "    try:\n",
    "        src_cat = butler.get('src', dataId=dataId)\n",
    "        calexp = butler.get('calexp', dataId=dataId)\n",
    "        calib = calexp.getPhotoCalib()\n",
    "        src_cat_df = src_cat.asAstropy()\n",
    "        src_cat_df = src_cat_df[['id', 'coord_ra', 'coord_dec',\n",
    "                                 'base_PsfFlux_instFlux']]\n",
    "        src_cat_df = src_cat_df.to_pandas()\n",
    "        mag = []\n",
    "        for src_flux in src_cat_df['base_PsfFlux_instFlux'].values:\n",
    "            mag.append(calib.instFluxToMagnitude(src_flux))\n",
    "        src_cat_df['mag'] = mag\n",
    "        if hsc_sources_df is None:\n",
    "            hsc_sources_df = pd.DataFrame([], columns=src_cat_df.columns)\n",
    "            hsc_sources_df = hsc_sources_df.append(src_cat_df, sort=False)\n",
    "        else:\n",
    "            hsc_sources_df = hsc_sources_df.append(src_cat_df, sort=False)\n",
    "        ccd_lims.append([np.degrees(np.max(src_cat_df['coord_ra'])),\n",
    "                         np.degrees(np.min(src_cat_df['coord_ra'])),\n",
    "                         np.degrees(np.max(src_cat_df['coord_dec'])),\n",
    "                         np.degrees(np.min(src_cat_df['coord_dec']))])\n",
    "    except daf_persistence.butlerExceptions.NoResults as inst:\n",
    "        print('No results for CCD #%i' % dataId['ccd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of HSC Sources\n",
    "len(hsc_sources_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsc_sources_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if faint_mag_lim is None:\n",
    "    hsc_final_df = hsc_sources_df\n",
    "else:\n",
    "    hsc_final_df = hsc_sources_df.query('mag < %f' % faint_mag_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsc_sources_coords = SkyCoord(hsc_final_df['coord_ra']*u.rad, hsc_final_df['coord_dec']*u.rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.scatter(hsc_sources_coords.ra.deg, hsc_sources_coords.dec.deg, s=8, lw=0)\n",
    "plt.xlabel('RA (deg)')\n",
    "plt.ylabel('dec (deg)')\n",
    "plt.title('HSC Sources in Visit %i' %visit)\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(ax.get_xticks()[1::2]) # Clean up ticks in RA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gaia data\n",
    "\n",
    "We have previously created a pandas dataframe with Gaia data that overlaps the HSC Wide data footprint. Here we load it in and select the data in the region of the visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in cached gaia data\n",
    "gaia_df = pd.read_pickle('/project/danielsf/gaia_hsc_overlap_pandas.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select data that falls in the bounds of the HSC CCDs\n",
    "gaia_visit_df = pd.DataFrame([], columns=gaia_df.columns)\n",
    "for ccd_corners in ccd_lims:\n",
    "    gaia_visit_df = gaia_visit_df.append(gaia_df.query('ra < %f and ra > %f and dec < %f and dec > %f' % (ccd_corners[0], ccd_corners[1],\n",
    "                                                                                                          ccd_corners[2], ccd_corners[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick low proper motion sources (gaia proper motions are in mas/year)\n",
    "low_pm = np.where((gaia_visit_df['pmra'] > -5) & (gaia_visit_df['pmra'] < 5) &\n",
    "                  (gaia_visit_df['pmdec'] > -5) & (gaia_visit_df['pmdec'] < 5))[0]\n",
    "gaia_visit_df = gaia_visit_df.iloc[low_pm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_coords = SkyCoord(gaia_visit_df['ra']*u.deg, gaia_visit_df['dec']*u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.scatter(gaia_coords.ra.deg, gaia_coords.dec.deg, s=8, lw=0)\n",
    "plt.xlabel('RA (deg)')\n",
    "plt.ylabel('dec (deg)')\n",
    "plt.title('Gaia Sources in Visit %i' %visit)\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(ax.get_xticks()[1::2]) # Clean up ticks in RA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use astropy to match each filter to r-band\n",
    "\n",
    "We will use the `match_to_catalog_sky` method from astropy to do the catalog match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_idx, sep2d, sep3d = gaia_coords.match_to_catalog_sky(hsc_sources_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.scatter(gaia_coords.ra.deg, gaia_coords.dec.deg, c=sep2d.arcsec*1000, s=20, vmax=50)\n",
    "cb = plt.colorbar()\n",
    "plt.xlabel('RA (deg)')\n",
    "plt.ylabel('dec (deg)')\n",
    "cb.set_label('Distance to match (milliarcsec)')\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(ax.get_xticks()[1::2]) # Clean up ticks in RA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make matched catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hsc_sources_coords to get everything in degrees\n",
    "matched_list = []\n",
    "for keep_idx, gaia_idx in zip(matched_idx, np.arange(len(gaia_coords))):\n",
    "    gaia_row = gaia_visit_df.iloc[gaia_idx]\n",
    "    hsc_row = hsc_final_df.iloc[keep_idx]\n",
    "    matched_list.append([hsc_row['id'], hsc_sources_coords[keep_idx].ra.deg,\n",
    "                         hsc_sources_coords[keep_idx].dec.deg,\n",
    "                         gaia_row['source_id'], gaia_row['ra'], gaia_row['dec']])\n",
    "matched_df = pd.DataFrame(matched_list, columns=['HSC_id', 'HSC_ra', 'HSC_dec', \n",
    "                                       'gaia_id', 'gaia_ra', 'gaia_dec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find separations in all pairs of sources\n",
    "\n",
    "The first thing we do is keep only the objects that appear in all visits so that we will have the best information available for the objects we use to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_objects = len(matched_df)\n",
    "print(\"Number of Objects present in all visits: %i\" % num_unique_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_objects = 200\n",
    "rand_state = np.random.RandomState(98)\n",
    "pairs_list = list(combinations(rand_state.choice(np.arange(num_unique_objects), \n",
    "                                                 size=use_objects, replace=False),\n",
    "                               2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_separations(catalog, pairs_list):\n",
    "    cat_seps = np.empty((len(pairs_list), 2))\n",
    "    hsc_locs = SkyCoord(catalog['HSC_ra']*u.deg, catalog['HSC_dec']*u.deg)\n",
    "    gaia_locs = SkyCoord(catalog['gaia_ra']*u.deg, catalog['gaia_dec']*u.deg)\n",
    "    seps = []\n",
    "    j = 0\n",
    "    for pair_1, pair_2 in pairs_list:\n",
    "        if j % 5000 == 0:\n",
    "            print('Calculating Separation %i out of %i' % (j, len(pairs_list)))\n",
    "        pair_seps = []\n",
    "        pair_seps.append(hsc_locs[pair_1].separation(hsc_locs[pair_2]).arcsec)\n",
    "        pair_seps.append(gaia_locs[pair_1].separation(gaia_locs[pair_2]).arcsec)\n",
    "        seps.append(pair_seps)\n",
    "        j += 1\n",
    "    cat_seps[:] = seps\n",
    "        \n",
    "    return cat_seps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_seps = calc_separations(matched_df, pairs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df = pd.DataFrame(visit_seps, columns=['sep_hsc', 'sep_gaia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df['diff'] = sep_df['sep_gaia'] - sep_df['sep_hsc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results against requirements\n",
    "\n",
    "Now break into Gaia Separations of 5, 20, 200 arcminutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 arcmin tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = 30 # Get 30 arcseconds on either side of defined separation\n",
    "five_arcmin = 60*5 # five arcminutes in arcseconds\n",
    "five_arcmin_df = sep_df.query('sep_gaia > %i-%i and sep_gaia < %i+%i' % (five_arcmin, lims,\n",
    "                                                                         five_arcmin, lims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "median_diff_5_arcmin = np.median(np.abs(five_arcmin_df['diff']))\n",
    "plt.hist(np.abs(five_arcmin_df['diff']), range=(0, 0.1))\n",
    "plt.axvline(median_diff_5_arcmin, 0, 1, \n",
    "            c='k', label='Median Difference: %.2f (mas)' % (median_diff_5_arcmin*1000), lw=4)\n",
    "plt.axvline(0.01, 0, 1, c='r', label='Requirement = 10 milliarcsec', lw=4)\n",
    "plt.legend()\n",
    "plt.xlabel('Difference in Measured Separation for sources separated by ~5 arcmin (arcsec)')\n",
    "plt.ylabel('Number of Pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "n, bins, _ = plt.hist(np.abs(five_arcmin_df['diff']), range=(0, 0.1),\n",
    "                      cumulative=True, density=True)\n",
    "current_outlier_frac_5 = n[np.where(bins < 0.02)[0][-1]]\n",
    "plt.axhline(current_outlier_frac_5, 0, 1, c='k', \n",
    "            label='Outlier Percentage = %.2f%s' % ((1.-current_outlier_frac_5)*100, '%'), \n",
    "            lw=4)\n",
    "plt.axhline(0.9, 0, 1, c='r', ls='--', label='90th percentile', lw=4)\n",
    "plt.axvline(0.020, 0, 1, c='r', label='Requirement: Outlier Fraction (> 20mas) <= 10%', lw=4)\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Difference in Measured Separation for sources separated by ~5 arcmin (arcsec)')\n",
    "plt.ylabel('Cumulative Fraction of Pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 arcmin tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = 30 # Get 30 arcseconds on either side of defined separation\n",
    "twenty_arcmin = 60*20 # 20 arcminutes in arcseconds\n",
    "twenty_arcmin_df = sep_df.query('sep_gaia > %i-%i and sep_gaia < %i+%i' % (twenty_arcmin, lims,\n",
    "                                                                           twenty_arcmin, lims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "median_diff_20_arcmin = np.median(np.abs(twenty_arcmin_df['diff']))\n",
    "plt.hist(np.abs(twenty_arcmin_df['diff']), range=(0, 0.1))\n",
    "plt.axvline(median_diff_20_arcmin, 0, 1, \n",
    "            c='k', label='Median Difference: %.2f (mas)' % (median_diff_20_arcmin*1000), lw=4)\n",
    "plt.axvline(0.01, 0, 1, c='r', label='Requirement = 10 milliarcsec', lw=4)\n",
    "plt.legend()\n",
    "plt.xlabel('Difference in Measured Separation for sources separated by ~20 arcmin (arcsec)')\n",
    "plt.ylabel('Number of Pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "n, bins, _ = plt.hist(np.abs(twenty_arcmin_df['diff']), range=(0, 0.1),\n",
    "                      cumulative=True, density=True)\n",
    "current_outlier_frac_20 = n[np.where(bins < 0.02)[0][-1]]\n",
    "plt.axhline(current_outlier_frac_20, 0, 1, c='k', \n",
    "            label='Outlier Percentage = %.2f%s' % ((1.-current_outlier_frac_20)*100, '%'), \n",
    "            lw=4)\n",
    "plt.axhline(0.9, 0, 1, c='r', ls='--', label='90th percentile', lw=4)\n",
    "plt.axvline(0.020, 0, 1, c='r', label='Requirement: Outlier Fraction (> 20mas) <= 10%', lw=4)\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Difference in Measured Separation for sources separated by ~20 arcmin (arcsec)')\n",
    "plt.ylabel('Cumulative Fraction of Pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 200 arcmin tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = 30 # Get 30 arcseconds on either side of defined separation\n",
    "two_hundred_arcmin = 60*200 # 200 arcminutes in arcseconds\n",
    "two_hundred_arcmin_df = sep_df.query('sep_gaia > %i-%i and sep_gaia < %i+%i' % (two_hundred_arcmin, \n",
    "                                                                                lims,\n",
    "                                                                                two_hundred_arcmin, \n",
    "                                                                                lims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "median_diff_200_arcmin = np.median(np.abs(two_hundred_arcmin_df['diff']))\n",
    "plt.hist(np.abs(two_hundred_arcmin_df['diff']), range=(0, 0.1))\n",
    "plt.axvline(median_diff_200_arcmin, 0, 1, \n",
    "            c='k', label='Median Difference: %.2f (mas)' % (median_diff_200_arcmin*1000), lw=4)\n",
    "plt.axvline(0.015, 0, 1, c='r', label='Requirement = 15 milliarcsec', lw=4)\n",
    "plt.legend()\n",
    "plt.xlabel('Difference in Measured Separation for sources separated by ~200 arcmin (arcsec)')\n",
    "plt.ylabel('Number of Pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "n, bins, _ = plt.hist(np.abs(two_hundred_arcmin_df['diff']), range=(0, 0.1),\n",
    "                      cumulative=True, density=True)\n",
    "current_outlier_frac_200 = n[np.where(bins < 0.02)[0][-1]]\n",
    "plt.axhline(current_outlier_frac_200, 0, 1, c='k', \n",
    "            label='Outlier Percentage = %.2f%s' % ((1.-current_outlier_frac_200)*100, '%'), \n",
    "            lw=4)\n",
    "plt.axhline(0.9, 0, 1, c='r', ls='--', label='90th percentile', lw=4)\n",
    "plt.axvline(0.030, 0, 1, c='r', label='Requirement: Outlier Fraction (> 30mas) <= 10%', lw=4)\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Difference in Measured Separation for sources separated by ~200 arcmin (arcsec)')\n",
    "plt.ylabel('Cumulative Fraction of Pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequirementFailure(ValueError):\n",
    "    \"Requirement not met.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for potential error messages\n",
    "error_msg = \"\"\n",
    "error_present = False\n",
    "error_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test separation differences on ~5 arcmin scale\n",
    "if median_diff_5_arcmin*1000. > 10.:\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val +\n",
    "                     'Failure differences in separations on ~5 arcmin scale greater than 10 milliarcsec. ' + \n",
    "                     'Test Value = %.2f mas. \\n' % (median_diff_5_arcmin*1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Outlier Fraction of separation differences on ~5 arcmin scale\n",
    "if (1.-current_outlier_frac_5)*100 > 10.:\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val + \n",
    "                     'Separation Difference Outlier Fraction on ~5 arcmin scales ' + \n",
    "                     '(differences in pair separations > 20 mas) ' +\n",
    "                     'is greater than 10%s. Test Value = %.2f%s \\n' % ('%', \n",
    "                                                                    (1.-current_outlier_frac_5)*100, \n",
    "                                                                    '%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test separation differences on ~20 arcmin scale\n",
    "if median_diff_20_arcmin*1000. > 10.:\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val +\n",
    "                     'Failure differences in separations on ~20 arcmin scale greater than 10 milliarcsec. ' + \n",
    "                     'Test Value = %.2f mas. \\n' % (median_diff_20_arcmin*1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Outlier Fraction of separation differences on ~20 arcmin scale\n",
    "if (1.-current_outlier_frac_20)*100 > 10.:\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val + \n",
    "                     'Separation Difference Outlier Fraction on ~20 arcmin scales ' + \n",
    "                     '(differences in pair separations > 20 mas) ' +\n",
    "                     'is greater than 10%s. Test Value = %.2f%s \\n' % ('%', \n",
    "                                                                    (1.-current_outlier_frac_20)*100, \n",
    "                                                                    '%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test separation differences on ~200 arcmin scale\n",
    "if median_diff_200_arcmin*1000. > 10.:\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val +\n",
    "                     'Failure differences in separations on ~200 arcmin scale greater than 15 milliarcsec. ' + \n",
    "                     'Test Value = %.2f mas. \\n' % (median_diff_200_arcmin*1000.))\n",
    "elif np.isnan(median_diff_200_arcmin):\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val +\n",
    "                     'Cannot calculate median difference in separations for objects '+\n",
    "                     'with 200 arcmin separation. No objects with 200 arcmin separation. Test value == nan. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Outlier Fraction of separation differences on ~200 arcmin scale\n",
    "if (1.-current_outlier_frac_200)*100 > 10.:\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val + \n",
    "                     'Separation Difference Outlier Fraction on ~200 arcmin scales ' + \n",
    "                     '(differences in pair separations > 30 mas) ' +\n",
    "                     'is greater than 10%s. Test Value = %.2f%s \\n' % ('%', \n",
    "                                                                    (1.-current_outlier_frac_200)*100, \n",
    "                                                                    '%'))\n",
    "elif np.isnan(current_outlier_frac_200):\n",
    "    error_present = True\n",
    "    error_val += 1\n",
    "    error_msg += str('Error #%i: \\n' % error_val +\n",
    "                     'Cannot calculate Separation Difference Outlier Fraction for objects '+\n",
    "                     'with 200 arcmin separation. No objects with 200 arcmin separation. Test value == nan. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if error_present is True:\n",
    "    error_msg = str('%i Total Errors: \\n' % error_val + error_msg)\n",
    "    raise RequirementFailure(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
